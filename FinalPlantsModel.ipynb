{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalPlantsModel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGETIKasQ49GxSzxMLuXRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShubhamGupta19/CnnBasedAndroidapp_plant_species_detection/blob/master/FinalPlantsModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJKcLD7iMyuj"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg4WNx42P5e9"
      },
      "source": [
        "from tensorflow.keras.callbacks import BaseLogger\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Activation\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "from tensorflow.keras.layers import AveragePooling2D\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from  tensorflow.keras.layers import concatenate\r\n",
        "from tensorflow.keras.layers import add\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from tensorflow.keras import Input\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import os\r\n",
        "import h5py       \r\n",
        "import cv2\r\n",
        "import imutils\r\n",
        "import glob"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v6os0KiQDyJ",
        "outputId": "358cb5b3-dd6c-4453-e390-7fc35e38eea7"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noMiU5DDQG2q"
      },
      "source": [
        "train_dir ='/content/drive/My Drive/PlantsProject/output/train'\r\n",
        "test_dir='/content/drive/My Drive/PlantsProject/output/val'"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxXYdySQmg3"
      },
      "source": [
        "def get_files(directory):\r\n",
        "  if not os.path.exists(directory):\r\n",
        "    return 0\r\n",
        "  count=0\r\n",
        "  for current_path,dirs,files in os.walk(directory):\r\n",
        "    for dr in dirs:\r\n",
        "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\r\n",
        "  return count"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZnRsI-8Qn_n",
        "outputId": "187c8ab9-dd74-41be-f5c0-a3031f3f262c"
      },
      "source": [
        "\r\n",
        "\r\n",
        "train_samples =get_files(train_dir)\r\n",
        "num_classes=len(glob.glob(train_dir+\"/*\"))\r\n",
        "test_samples=get_files(test_dir)\r\n",
        "print(num_classes,\"Classes\")\r\n",
        "print(train_samples,\"Train images\")\r\n",
        "print(test_samples,\"Test images\")\r\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 Classes\n",
            "1200 Train images\n",
            "400 Test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P46Cr4jQptX"
      },
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,\r\n",
        "                                   shear_range=0.2,\r\n",
        "                                   zoom_range=0.2,\r\n",
        "                                   horizontal_flip=True)\r\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkX-OraLQ330",
        "outputId": "84e93398-6bc9-42d1-a336-d5df12b215b9"
      },
      "source": [
        "\r\n",
        "# set height and width and color of input image.\r\n",
        "img_width,img_height =256,256\r\n",
        "input_shape=(img_width,img_height,3)\r\n",
        "batch_size =32\r\n",
        "train_generator =train_datagen.flow_from_directory(train_dir,target_size=(img_width,img_height), batch_size=batch_size)\r\n",
        "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,target_size=(img_width,img_height),batch_size=batch_size)\r\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1200 images belonging to 100 classes.\n",
            "Found 400 images belonging to 100 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeJXA02mRETw",
        "outputId": "ce0487e3-afc0-4a55-b1a2-01969ab2fcd0"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Acer_Campestre': 0,\n",
              " 'Acer_Capillipes': 1,\n",
              " 'Acer_Circinatum': 2,\n",
              " 'Acer_Mono': 3,\n",
              " 'Acer_Opalus': 4,\n",
              " 'Acer_Palmatum': 5,\n",
              " 'Acer_Pictum': 6,\n",
              " 'Acer_Platanoids': 7,\n",
              " 'Acer_Rubrum': 8,\n",
              " 'Acer_Rufinerve': 9,\n",
              " 'Acer_Saccharinum': 10,\n",
              " 'Alnus_Cordata': 11,\n",
              " 'Alnus_Maximowiczii': 12,\n",
              " 'Alnus_Rubra': 13,\n",
              " 'Alnus_Sieboldiana': 14,\n",
              " 'Alnus_Viridis': 15,\n",
              " 'Arundinaria_Simonii': 16,\n",
              " 'Betula_Austrosinensis': 17,\n",
              " 'Betula_Pendula': 18,\n",
              " 'Callicarpa_Bodinieri': 19,\n",
              " 'Castanea_Sativa': 20,\n",
              " 'Celtis_Koraiensis': 21,\n",
              " 'Cercis_Siliquastrum': 22,\n",
              " 'Cornus_Chinensis': 23,\n",
              " 'Cornus_Controversa': 24,\n",
              " 'Cornus_Macrophylla': 25,\n",
              " 'Cotinus_Coggygria': 26,\n",
              " 'Crataegus_Monogyna': 27,\n",
              " 'Cytisus_Battandieri': 28,\n",
              " 'Eucalyptus_Glaucescens': 29,\n",
              " 'Eucalyptus_Neglecta': 30,\n",
              " 'Eucalyptus_Urnigera': 31,\n",
              " 'Fagus_Sylvatica': 32,\n",
              " 'Ginkgo_Biloba': 33,\n",
              " 'Ilex_Aquifolium': 34,\n",
              " 'Ilex_Cornuta': 35,\n",
              " 'Liquidambar_Styraciflua': 36,\n",
              " 'Liriodendron_Tulipifera': 37,\n",
              " 'Lithocarpus_Cleistocarpus': 38,\n",
              " 'Lithocarpus_Edulis': 39,\n",
              " 'Magnolia_Heptapeta': 40,\n",
              " 'Magnolia_Salicifolia': 41,\n",
              " 'Morus_Nigra': 42,\n",
              " 'Olea_Europaea': 43,\n",
              " 'Phildelphus': 44,\n",
              " 'Populus_Adenopoda': 45,\n",
              " 'Populus_Grandidentata': 46,\n",
              " 'Populus_Nigra': 47,\n",
              " 'Prunus_Avium': 48,\n",
              " 'Prunus_X_Shmittii': 49,\n",
              " 'Pterocarya_Stenoptera': 50,\n",
              " 'Quercus_Afares': 51,\n",
              " 'Quercus_Agrifolia': 52,\n",
              " 'Quercus_Alnifolia': 53,\n",
              " 'Quercus_Brantii': 54,\n",
              " 'Quercus_Canariensis': 55,\n",
              " 'Quercus_Castaneifolia': 56,\n",
              " 'Quercus_Cerris': 57,\n",
              " 'Quercus_Chrysolepis': 58,\n",
              " 'Quercus_Coccifera': 59,\n",
              " 'Quercus_Coccinea': 60,\n",
              " 'Quercus_Crassifolia': 61,\n",
              " 'Quercus_Crassipes': 62,\n",
              " 'Quercus_Dolicholepis': 63,\n",
              " 'Quercus_Ellipsoidalis': 64,\n",
              " 'Quercus_Greggii': 65,\n",
              " 'Quercus_Hartwissiana': 66,\n",
              " 'Quercus_Ilex': 67,\n",
              " 'Quercus_Imbricaria': 68,\n",
              " 'Quercus_Infectoria_sub': 69,\n",
              " 'Quercus_Kewensis': 70,\n",
              " 'Quercus_Nigra': 71,\n",
              " 'Quercus_Palustris': 72,\n",
              " 'Quercus_Phellos': 73,\n",
              " 'Quercus_Phillyraeoides': 74,\n",
              " 'Quercus_Pontica': 75,\n",
              " 'Quercus_Pubescens': 76,\n",
              " 'Quercus_Pyrenaica': 77,\n",
              " 'Quercus_Rhysophylla': 78,\n",
              " 'Quercus_Rubra': 79,\n",
              " 'Quercus_Semecarpifolia': 80,\n",
              " 'Quercus_Shumardii': 81,\n",
              " 'Quercus_Suber': 82,\n",
              " 'Quercus_Texana': 83,\n",
              " 'Quercus_Trojana': 84,\n",
              " 'Quercus_Variabilis': 85,\n",
              " 'Quercus_Vulcanica': 86,\n",
              " 'Quercus_x_Hispanica': 87,\n",
              " 'Quercus_x_Turneri': 88,\n",
              " 'Rhododendron_x_Russellianum': 89,\n",
              " 'Salix_Fragilis': 90,\n",
              " 'Salix_Intergra': 91,\n",
              " 'Sorbus_Aria': 92,\n",
              " 'Tilia_Oliveri': 93,\n",
              " 'Tilia_Platyphyllos': 94,\n",
              " 'Tilia_Tomentosa': 95,\n",
              " 'Ulmus_Bergmanniana': 96,\n",
              " 'Viburnum_Tinus': 97,\n",
              " 'Viburnum_x_Rhytidophylloides': 98,\n",
              " 'Zelkova_Serrata': 99}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDRl1sR5eFyL"
      },
      "source": [
        "class MiniGoogLeNet:\r\n",
        "  @staticmethod\r\n",
        "  def conv_module(x,K,kX,kY,stride,chanDim,padding=\"same\"):\r\n",
        "    x=Conv2D(K,(kX,kY),strides=stride,padding=padding)(x)\r\n",
        "    x=BatchNormalization(axis=chanDim)(x)\r\n",
        "    x=Activation(\"relu\")(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def inception_module(x,numK1x1,numK3x3,chanDim):\r\n",
        "    conv_1x1=MiniGoogLeNet.conv_module(x,numK1x1,1,1,(1,1),chanDim)\r\n",
        "    conv_3x3=MiniGoogLeNet.conv_module(x,numK3x3,3,3,(1,1),chanDim)\r\n",
        "    x=concatenate([conv_1x1,conv_3x3],axis=chanDim)\r\n",
        "    return x\r\n",
        "\r\n",
        "  @staticmethod \r\n",
        "  def downsample_module(x,K,chanDim):\r\n",
        "    conv_3x3=MiniGoogLeNet.conv_module(x,K,3,3,(2,2),chanDim,padding=\"valid\")\r\n",
        "    pool=MaxPooling2D((3,3),strides=(2,2))(x)\r\n",
        "    x=concatenate([conv_3x3,pool],axis=chanDim)\r\n",
        "    return x\r\n",
        "  \r\n",
        "  def build(width,height,depth,classes):\r\n",
        "    inputShape=(height,width,depth)\r\n",
        "    chanDim=-1\r\n",
        "    if K.image_data_format()==\"channels_first\":\r\n",
        "      inputShape=(depth,height,width)\r\n",
        "      chanDim= 1\r\n",
        "    inputs=Input(shape=inputShape)\r\n",
        "    x=MiniGoogLeNet.conv_module(inputs,96,3,3,(1,1),chanDim)\r\n",
        "    x=MiniGoogLeNet.inception_module(x,32,32,chanDim)\r\n",
        "    x=MiniGoogLeNet.downsample_module(x,80,chanDim)\r\n",
        "    x=MiniGoogLeNet.inception_module(x,112,48,chanDim)\r\n",
        "    x=MiniGoogLeNet.inception_module(x,96,64,chanDim)\r\n",
        "    x=MiniGoogLeNet.inception_module(x,80,80,chanDim)\r\n",
        "    x=MiniGoogLeNet.inception_module(x,48,96,chanDim)\r\n",
        "    x=MiniGoogLeNet.downsample_module(x,96,chanDim)\r\n",
        "    x=MiniGoogLeNet.inception_module(x,176,160,chanDim)\r\n",
        "    x=MiniGoogLeNet.inception_module(x,176,160,chanDim)\r\n",
        "    x=AveragePooling2D((7,7))(x)\r\n",
        "    x=Dropout(0.5)(x)\r\n",
        "\r\n",
        "    x=Flatten()(x)\r\n",
        "    x=Dense(classes)(x)\r\n",
        "    x=Activation(\"softmax\")(x)\r\n",
        "\r\n",
        "    model=Model(inputs,x,name=\"googlenet\")\r\n",
        "    return model\r\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "M6lv_A2CRHaP",
        "outputId": "b1697351-8ead-4799-fc1d-1267e024525e"
      },
      "source": [
        "\r\n",
        "from keras.preprocessing import image\r\n",
        "import numpy as np\r\n",
        "img1 = image.load_img('/content/drive/My Drive/PlantsProject/output/train/Acer_Campestre/Acer_Campestre_01.ab.jpg')\r\n",
        "plt.imshow(img1);\r\n",
        "#preprocess image\r\n",
        "img1 = image.load_img('/content/drive/My Drive/PlantsProject/output/train/Acer_Campestre/Acer_Campestre_02.ab.jpg', target_size=(256, 256))\r\n",
        "img = image.img_to_array(img1)\r\n",
        "img = img/255\r\n",
        "img = np.expand_dims(img, axis=0)\r\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_cWVPDze92A"
      },
      "source": [
        "aug=ImageDataGenerator(\r\n",
        "        width_shift_range=0.1,\r\n",
        "        height_shift_range=0.1,\r\n",
        "        horizontal_flip=True,\r\n",
        "        fill_mode=\"nearest\"\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPm9z4uoeTSp"
      },
      "source": [
        "NUM_EPOCHS=70\r\n",
        "INIT_LR=5e-3"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZyG0wJgU4-r",
        "outputId": "ee9846c9-e026-4748-e4c7-803b6db40253"
      },
      "source": [
        "print(\"[INFO] Compiling model\")\r\n",
        "opt=SGD(lr=INIT_LR,momentum=0.9)\r\n",
        "model=MiniGoogLeNet.build(width=256,height=256,depth=3,classes=num_classes)\r\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=['accuracy'])\r\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Compiling model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCH88Me02PBM",
        "outputId": "888f5e53-2059-4bd8-8fd2-632a01aacd37"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"googlenet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 96) 2688        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 96) 384         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 96) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 32) 3104        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 32) 27680       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 32) 128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 256, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256, 256, 64) 0           activation_1[0][0]               \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 127, 127, 80) 46160       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 127, 127, 80) 320         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 127, 127, 80) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 127, 127, 64) 0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 127, 127, 144 0           activation_3[0][0]               \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 127, 127, 112 16240       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 127, 127, 48) 62256       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 127, 127, 112 448         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 127, 127, 48) 192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 127, 127, 112 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 127, 127, 48) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 127, 127, 160 0           activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 127, 127, 96) 15456       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 127, 127, 64) 92224       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 127, 127, 96) 384         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 127, 127, 64) 256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 127, 127, 96) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 127, 127, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 127, 127, 160 0           activation_6[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 127, 127, 80) 12880       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 127, 127, 80) 115280      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 127, 127, 80) 320         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 127, 127, 80) 320         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 127, 127, 80) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 127, 127, 80) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 127, 127, 160 0           activation_8[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 127, 127, 48) 7728        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 127, 127, 96) 138336      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 127, 127, 48) 192         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 127, 127, 96) 384         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 127, 127, 48) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 127, 127, 96) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 127, 127, 144 0           activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 63, 63, 96)   124512      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 63, 63, 96)   384         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 63, 63, 96)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 63, 63, 144)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 63, 63, 240)  0           activation_12[0][0]              \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 63, 63, 176)  42416       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 63, 63, 160)  345760      concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 63, 63, 176)  704         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 63, 63, 160)  640         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 63, 63, 176)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 63, 63, 160)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 63, 63, 336)  0           activation_13[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 63, 63, 176)  59312       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 63, 63, 160)  484000      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 63, 63, 176)  704         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 63, 63, 160)  640         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 63, 63, 176)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 63, 63, 160)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 63, 63, 336)  0           activation_15[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 9, 9, 336)    0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 9, 9, 336)    0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 27216)        0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          2721700     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 100)          0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,324,260\n",
            "Trainable params: 4,320,996\n",
            "Non-trainable params: 3,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw_mao8wc__A"
      },
      "source": [
        "model.fit(aug.flow(trainX,trainY,batch_size=64), validation_data=(testX,testY),steps_per_epoch=len(trainX)//64, epochs=NUM_EPOCHS,callbacks=callbacks,verbose=1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owhpDXzJfnvp",
        "outputId": "929c3bba-917d-41a8-8b76-6faf87868fd8"
      },
      "source": [
        "train=model.fit_generator(train_generator,epochs=100,steps_per_epoch=train_generator.samples//batch_size,validation_data=test_generator,validation_steps=test_generator.samples // batch_size,verbose=1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "37/37 [==============================] - 367s 10s/step - loss: 5.0708 - accuracy: 0.0354 - val_loss: 4.6053 - val_accuracy: 0.0260\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 4.1325 - accuracy: 0.1446 - val_loss: 4.6769 - val_accuracy: 0.0208\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 3.3774 - accuracy: 0.2249 - val_loss: 4.6656 - val_accuracy: 0.0260\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 2.7572 - accuracy: 0.3262 - val_loss: 4.4632 - val_accuracy: 0.0234\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 2.5954 - accuracy: 0.3733 - val_loss: 4.0596 - val_accuracy: 0.0677\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 2.3392 - accuracy: 0.4373 - val_loss: 4.1230 - val_accuracy: 0.0521\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 2.1504 - accuracy: 0.4664 - val_loss: 3.3865 - val_accuracy: 0.2083\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.9528 - accuracy: 0.4939 - val_loss: 3.1748 - val_accuracy: 0.2552\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.6912 - accuracy: 0.5535 - val_loss: 2.9657 - val_accuracy: 0.3047\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.6750 - accuracy: 0.5400 - val_loss: 2.2055 - val_accuracy: 0.4297\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.7270 - accuracy: 0.5444 - val_loss: 1.7591 - val_accuracy: 0.5078\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.3873 - accuracy: 0.6138 - val_loss: 1.6120 - val_accuracy: 0.5443\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.3651 - accuracy: 0.6242 - val_loss: 1.3642 - val_accuracy: 0.5938\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.2792 - accuracy: 0.6576 - val_loss: 1.4159 - val_accuracy: 0.6016\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.3354 - accuracy: 0.6430 - val_loss: 2.1346 - val_accuracy: 0.4583\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.1548 - accuracy: 0.6923 - val_loss: 1.4430 - val_accuracy: 0.5599\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.1203 - accuracy: 0.6860 - val_loss: 1.6820 - val_accuracy: 0.5443\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.1213 - accuracy: 0.6885 - val_loss: 1.3506 - val_accuracy: 0.6120\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.0385 - accuracy: 0.6899 - val_loss: 1.1513 - val_accuracy: 0.6536\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.9900 - accuracy: 0.7056 - val_loss: 1.1525 - val_accuracy: 0.6745\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 1.1170 - accuracy: 0.6775 - val_loss: 4.2813 - val_accuracy: 0.3073\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.8755 - accuracy: 0.7426 - val_loss: 1.0733 - val_accuracy: 0.6745\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.9373 - accuracy: 0.7141 - val_loss: 1.1670 - val_accuracy: 0.6380\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.8995 - accuracy: 0.7409 - val_loss: 1.2004 - val_accuracy: 0.6406\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.8595 - accuracy: 0.7553 - val_loss: 1.2864 - val_accuracy: 0.6484\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.8576 - accuracy: 0.7406 - val_loss: 1.0463 - val_accuracy: 0.7188\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.7328 - accuracy: 0.7966 - val_loss: 8.1223 - val_accuracy: 0.1823\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.7193 - accuracy: 0.7762 - val_loss: 3.8279 - val_accuracy: 0.3542\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.7598 - accuracy: 0.7784 - val_loss: 1.4159 - val_accuracy: 0.6094\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.6855 - accuracy: 0.8053 - val_loss: 1.0768 - val_accuracy: 0.6953\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.6646 - accuracy: 0.8252 - val_loss: 1.1113 - val_accuracy: 0.7031\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.6631 - accuracy: 0.8073 - val_loss: 0.9846 - val_accuracy: 0.7188\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.6579 - accuracy: 0.7998 - val_loss: 1.0806 - val_accuracy: 0.6901\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.6161 - accuracy: 0.8112 - val_loss: 1.1455 - val_accuracy: 0.6719\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.6505 - accuracy: 0.7934 - val_loss: 0.9710 - val_accuracy: 0.6771\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.5807 - accuracy: 0.8283 - val_loss: 5.2460 - val_accuracy: 0.3021\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.5367 - accuracy: 0.8331 - val_loss: 1.0951 - val_accuracy: 0.6875\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.6377 - accuracy: 0.8265 - val_loss: 1.2089 - val_accuracy: 0.6536\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.5964 - accuracy: 0.8254 - val_loss: 0.9345 - val_accuracy: 0.7109\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.5384 - accuracy: 0.8390 - val_loss: 0.8717 - val_accuracy: 0.7396\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.5502 - accuracy: 0.8509 - val_loss: 0.8087 - val_accuracy: 0.7917\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 44s 1s/step - loss: 0.5222 - accuracy: 0.8382 - val_loss: 0.9516 - val_accuracy: 0.7083\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4232 - accuracy: 0.8872 - val_loss: 0.9195 - val_accuracy: 0.7396\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4925 - accuracy: 0.8379 - val_loss: 0.8860 - val_accuracy: 0.7344\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4452 - accuracy: 0.8668 - val_loss: 1.0504 - val_accuracy: 0.7005\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4738 - accuracy: 0.8754 - val_loss: 0.7091 - val_accuracy: 0.7891\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4465 - accuracy: 0.8810 - val_loss: 1.0213 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4583 - accuracy: 0.8553 - val_loss: 0.7709 - val_accuracy: 0.7734\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4572 - accuracy: 0.8576 - val_loss: 1.3029 - val_accuracy: 0.6875\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3456 - accuracy: 0.9002 - val_loss: 0.7263 - val_accuracy: 0.7839\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4175 - accuracy: 0.8873 - val_loss: 2.9429 - val_accuracy: 0.4479\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4675 - accuracy: 0.8590 - val_loss: 0.8940 - val_accuracy: 0.7656\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4376 - accuracy: 0.8562 - val_loss: 0.8428 - val_accuracy: 0.7552\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4265 - accuracy: 0.8830 - val_loss: 0.8657 - val_accuracy: 0.7656\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3550 - accuracy: 0.8956 - val_loss: 1.4651 - val_accuracy: 0.6328\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3544 - accuracy: 0.8855 - val_loss: 1.0432 - val_accuracy: 0.7266\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4117 - accuracy: 0.8763 - val_loss: 0.8839 - val_accuracy: 0.7552\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.4080 - accuracy: 0.8672 - val_loss: 1.0672 - val_accuracy: 0.7135\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3570 - accuracy: 0.8931 - val_loss: 0.7146 - val_accuracy: 0.7891\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3274 - accuracy: 0.8978 - val_loss: 0.9861 - val_accuracy: 0.7474\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3612 - accuracy: 0.8923 - val_loss: 1.0737 - val_accuracy: 0.7135\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3615 - accuracy: 0.8879 - val_loss: 0.7763 - val_accuracy: 0.7786\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2701 - accuracy: 0.9174 - val_loss: 0.8686 - val_accuracy: 0.7656\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2744 - accuracy: 0.9168 - val_loss: 0.8419 - val_accuracy: 0.7734\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2870 - accuracy: 0.9145 - val_loss: 4.2956 - val_accuracy: 0.3724\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3386 - accuracy: 0.8951 - val_loss: 0.7935 - val_accuracy: 0.7656\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3008 - accuracy: 0.9061 - val_loss: 0.8193 - val_accuracy: 0.7760\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2464 - accuracy: 0.9287 - val_loss: 0.9704 - val_accuracy: 0.7214\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2477 - accuracy: 0.9249 - val_loss: 3.1372 - val_accuracy: 0.4792\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2455 - accuracy: 0.9178 - val_loss: 0.6967 - val_accuracy: 0.8047\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2717 - accuracy: 0.9155 - val_loss: 0.8067 - val_accuracy: 0.7734\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2839 - accuracy: 0.9231 - val_loss: 1.0178 - val_accuracy: 0.7214\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2587 - accuracy: 0.9183 - val_loss: 0.6624 - val_accuracy: 0.8099\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3869 - accuracy: 0.8830 - val_loss: 2.5990 - val_accuracy: 0.5443\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.3122 - accuracy: 0.9039 - val_loss: 1.0807 - val_accuracy: 0.7292\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2851 - accuracy: 0.9128 - val_loss: 0.9507 - val_accuracy: 0.7370\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 44s 1s/step - loss: 0.2198 - accuracy: 0.9293 - val_loss: 1.0668 - val_accuracy: 0.7240\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2607 - accuracy: 0.9197 - val_loss: 1.4573 - val_accuracy: 0.6250\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2426 - accuracy: 0.9246 - val_loss: 1.2514 - val_accuracy: 0.6979\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.1915 - accuracy: 0.9423 - val_loss: 1.1993 - val_accuracy: 0.7188\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2428 - accuracy: 0.9315 - val_loss: 1.9073 - val_accuracy: 0.6094\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2514 - accuracy: 0.9276 - val_loss: 0.6557 - val_accuracy: 0.8151\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2337 - accuracy: 0.9345 - val_loss: 1.0373 - val_accuracy: 0.7109\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2808 - accuracy: 0.9135 - val_loss: 0.6939 - val_accuracy: 0.8073\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2455 - accuracy: 0.9249 - val_loss: 2.6147 - val_accuracy: 0.4948\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2084 - accuracy: 0.9333 - val_loss: 0.6811 - val_accuracy: 0.8177\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2306 - accuracy: 0.9273 - val_loss: 0.7341 - val_accuracy: 0.8229\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2331 - accuracy: 0.9331 - val_loss: 0.7722 - val_accuracy: 0.7708\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2764 - accuracy: 0.9070 - val_loss: 7.1288 - val_accuracy: 0.2604\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2108 - accuracy: 0.9395 - val_loss: 0.6688 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.1626 - accuracy: 0.9493 - val_loss: 0.8102 - val_accuracy: 0.7839\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.1421 - accuracy: 0.9506 - val_loss: 0.8298 - val_accuracy: 0.7891\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.1741 - accuracy: 0.9472 - val_loss: 0.6203 - val_accuracy: 0.8359\n",
            "Epoch 94/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2108 - accuracy: 0.9318 - val_loss: 1.3407 - val_accuracy: 0.6875\n",
            "Epoch 95/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2376 - accuracy: 0.9181 - val_loss: 1.3564 - val_accuracy: 0.6797\n",
            "Epoch 96/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2255 - accuracy: 0.9256 - val_loss: 0.7983 - val_accuracy: 0.7943\n",
            "Epoch 97/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.2492 - accuracy: 0.9239 - val_loss: 0.8314 - val_accuracy: 0.7630\n",
            "Epoch 98/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.1888 - accuracy: 0.9462 - val_loss: 0.6539 - val_accuracy: 0.8281\n",
            "Epoch 99/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.1713 - accuracy: 0.9451 - val_loss: 0.8754 - val_accuracy: 0.7708\n",
            "Epoch 100/100\n",
            "37/37 [==============================] - 43s 1s/step - loss: 0.1631 - accuracy: 0.9502 - val_loss: 1.8984 - val_accuracy: 0.6172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF24pFZuoL7Q",
        "outputId": "f4e5cb78-41da-4185-8e7a-bbb5a1a7ebf9"
      },
      "source": [
        "print(\"[INFO] Serializing Network\")\r\n",
        "model.save(r\"/content/drive/My Drive/minigooglenet_plants.h5\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Serializing Network\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}